{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f53b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b74375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88bed74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([' Current Liability to Liability', ' Net Income Flag'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7baae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30477381",
   "metadata": {},
   "source": [
    "# Separating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c45973",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Bankrupt?'], axis = 1)\n",
    "y = df['Bankrupt?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea246009",
   "metadata": {},
   "source": [
    "# Selecting features with the K-best method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82942da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "transformer = MinMaxScaler().fit(X1)\n",
    "x_normalized = transformer.transform(X1)\n",
    "X2 = pd.DataFrame(x_normalized, columns= X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "kbest = SelectKBest(chi2, k=40) # Here we choose 10 best features so that is easier to analyze results later\n",
    "kbest.fit(X2,y)\n",
    "X_new = kbest.transform(X2) \n",
    "selected_columns = [X2.columns[index] for index, value in enumerate(kbest.get_support().tolist()) if value == True]\n",
    "selected = pd.DataFrame(X_new, columns = selected_columns)\n",
    "selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = [elem for elem in zip(kbest.scores_, X2.columns.tolist())]\n",
    "ml.sort(reverse=True)\n",
    "scores = pd.DataFrame(data = ml, columns = ['score','Column'])\n",
    "scores.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362916b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533912b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb67523",
   "metadata": {},
   "source": [
    "# Balancing the dataset: upsampling and downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.concat([selected, y], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad462f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_1['Bankrupt?'].astype('int')\n",
    "X = df_1.drop(['Bankrupt?'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4672631",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.concat([X_train, y_train], axis=1)\n",
    "TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "(TRAIN[TRAIN[\"Bankrupt?\"]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478991e",
   "metadata": {},
   "source": [
    "## Upsampling the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_indexes = np.random.choice(TRAIN[TRAIN[\"Bankrupt?\"]==1].index, size = 400, replace=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample = TRAIN.loc[upsample_indexes,:]\n",
    "upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d104f7",
   "metadata": {},
   "source": [
    "## Clustering to downsize the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_bankrupcies =  TRAIN[(TRAIN['Bankrupt?'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534fadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(2, 21)\n",
    "\n",
    "inertia = []\n",
    "silhouette = []\n",
    "\n",
    "for k in K:\n",
    "    print(\"Training a K-Means model with {} clusters! \".format(k))\n",
    "    print()\n",
    "    kmeans = KMeans(n_clusters=k,\n",
    "                    random_state=1234,\n",
    "                    verbose=1)\n",
    "    kmeans.fit(No_bankrupcies)\n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette.append(silhouette_score(No_bankrupcies, kmeans.predict(No_bankrupcies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32facd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "ax[0].plot(K, inertia, 'bx-')\n",
    "ax[0].set_xlabel('k')\n",
    "ax[0].set_ylabel('inertia')\n",
    "ax[0].set_xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "ax[0].set_title('Elbow Method showing the optimal k')\n",
    "ax[1].plot(K, silhouette, 'bx-')\n",
    "ax[1].set_xlabel('k')\n",
    "ax[1].set_ylabel('silhouette score')\n",
    "ax[1].set_xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "ax[1].set_title('Silhouette Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedee1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=9, random_state=1)\n",
    "kmeans.fit(No_bankrupcies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(No_bankrupcies)\n",
    "\n",
    "elem_in_cluster = pd.Series(clusters).value_counts().sort_index() # Number of values in each cluster\n",
    "elem_in_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_weight = []\n",
    "for j in range(len(elem_in_cluster)):\n",
    "    weight = elem_in_cluster[j]/len(No_bankrupcies)\n",
    "    clusters_weight.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_bankrupcies[\"cluster\"] = clusters\n",
    "No_bankrupcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0592c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_No_bankrupcies = pd.DataFrame(columns=No_bankrupcies.columns, dtype=float)\n",
    " \n",
    "for cluster, weight in enumerate(clusters_weight):\n",
    "    new_No_bankrupcies = pd.concat([new_No_bankrupcies, No_bankrupcies[No_bankrupcies[\"cluster\"]==cluster].sample(round(400*weight))], axis=0)\n",
    "    \n",
    "new_No_bankrupcies.drop(columns=['cluster'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073490ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final1_df = pd.concat([new_No_bankrupcies, upsample], axis=0)\n",
    "final1_df = final1_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0641b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = final1_df['Bankrupt?'].astype('int')\n",
    "X_train = final1_df.drop(['Bankrupt?'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada9393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b661c99d",
   "metadata": {},
   "source": [
    "# Predicting with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar distintos modelos con distintos valores de k\n",
    "K = range(2, 14, 3)\n",
    "accuracies = []\n",
    "models = []\n",
    "\n",
    "for k in K:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights = 'uniform') \n",
    "    knn.fit(X_train, y_train)\n",
    "    models.append(knn)\n",
    "    ypred_train = knn.predict(X_train)\n",
    "    accuracies.append(accuracy_score(y_train, ypred_train))\n",
    "    print(\"The accuracy of the model n_neighbors={} is: {:.2f}\".format(k, accuracy_score(y_train, ypred_train)))\n",
    "    print(\"The kappa of the model n_neighbors={} is: {:.2f}\".format(k, cohen_kappa_score(y_train, ypred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3eb7d0",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "pickel.dump(models[0], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278eebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(2, 14, 3)\n",
    "#accuracies = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    #knn = KNeighborsClassifier(n_neighbors=k) \n",
    "    knn = models[i]\n",
    "    ypred_test = knn.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, ypred_test))\n",
    "    print(\"The accuracy of the model n_neighbors={} is: {:.2f}\".format(list(K)[i], accuracy_score(y_test, ypred_test)))\n",
    "    print(\"The kappa score of the model n_neighbors={} is: {:.2f}\".format(list(K)[i],cohen_kappa_score(y_test, ypred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f961f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2) \n",
    "knn.fit(X_train, y_train)\n",
    "ypred_train = knn.predict(X_train)\n",
    "ypred_test = knn.predict(X_test)\n",
    "display(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(confusion_matrix(ypred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad5f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(confusion_matrix(ypred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28443f5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8353638",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=4,\n",
    "                             min_samples_split=6,\n",
    "                             min_samples_leaf =3,\n",
    "                             max_samples=0.8, random_state=8)\n",
    "                            \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The accuracy for the Random Forest in the TRAIN set is {:.2f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"The accuracy for the Random Forest in the TEST set is {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(y.value_counts())\n",
    "display(confusion_matrix(y_train, y_pred))\n",
    "display(cohen_kappa_score(y_train, y_pred))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(y.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))\n",
    "display(cohen_kappa_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "max_depth_choices= [2, 3, 5,7,9] \n",
    "min_samples_split_choices = [2,4,6,8,9]  \n",
    "min_samples_leaf_choices = [1,3] \n",
    "max_samples=[0.8,0.5]\n",
    "#n_jobs = [-1]\n",
    "\n",
    "grid = {'max_depth': max_depth_choices,\n",
    "        'min_samples_split': min_samples_split_choices,\n",
    "        'min_samples_leaf': min_samples_leaf_choices,\n",
    "        'max_samples':max_samples}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = 5) \n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767875ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(**grid_search.best_params_, random_state =8)\n",
    "                          \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"The accuracy for the Random Forest in the TRAIN set is {:.2f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"The accuracy for the Random Forest in the TEST set is {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(y.value_counts())\n",
    "display(confusion_matrix(y_train, y_pred))\n",
    "display(cohen_kappa_score(y_train, y_pred))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(y.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))\n",
    "display(cohen_kappa_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3913b",
   "metadata": {},
   "source": [
    "## Feature Extraction-SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12509063",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5551a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(' Persistent EPS in the Last Four Seasons', shap_values[0], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60332121",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8614df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ac396",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb823d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy for the XGB in the TRAIN set is {:.2f}\".format(xgb_cl.score(X_train, y_train)))\n",
    "print(\"The accuracy for the XGB in the TEST set is {:.2f}\".format(xgb_cl.score(X_test, y_test)))\n",
    "\n",
    "y_pred = pd.Series(xgb_cl.predict(X_train))\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(confusion_matrix(y_train, y_pred))\n",
    "display(cohen_kappa_score(y_train, y_pred))\n",
    "\n",
    "y_pred = pd.Series(xgb_cl.predict(X_test))\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))\n",
    "display(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b27be1",
   "metadata": {},
   "source": [
    "Learning_rate: also called eta, it specifies how quickly the model fits the residual errors by using additional base learners.typical values: 0.01–0.2\n",
    "\n",
    "Gamma, reg_alpha, reg_lambda: these 3 parameters specify the values for 3 types of regularization done by XGBoost - minimum loss reduction to create a new split, L1 reg on leaf weights, L2 reg leaf weights respectively.Typical values for gamma: 0 - 0.5 but highly dependent on the data. Typical values for reg_alpha and reg_lambda: 0 - 1 is a good starting point but again, depends on the data.\n",
    "\n",
    "Max_depth - how deep the tree's decision nodes can go. Must be a positive integer. typical values: 1–10\n",
    "\n",
    "Subsample - fraction of the training set that can be used to train each tree. If this value is low, it may lead to underfitting or if it is too high, it may lead to overfitting. typical values: 0.5–0.9\n",
    "\n",
    "Colsample_bytree- fraction of the features that can be used to train each tree. A large value means almost all features can be used to build the decision tree. typical values: 0.5–0.9\n",
    "\n",
    "The above are the main hyperparameters people often tune. It is perfectly OK if you don’t understand them all completely (like me) but you can refer to this post which gives a thorough overview of how each of the above parameters works and how to tune them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b44ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.2],\n",
    "    \"gamma\": [0, 0.5, 1],\n",
    "    \"reg_lambda\": [0, 0.5, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    \"reg_alpha\": [0, 0.5, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c051e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# Init Grid Search\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "\n",
    "# Fit\n",
    "_ = grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b171da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f841bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cl = xgb.XGBClassifier(\n",
    "    **grid_cv.best_params_,\n",
    "    objective=\"binary:logistic\")\n",
    "_ = final_cl.fit(X_train, y_train)\n",
    "preds = final_cl.predict(X_test)\n",
    "\n",
    "print(\"The accuracy for the XGB in the TRAIN set is {:.2f}\".format(final_cl.score(X_train, y_train)))\n",
    "print(\"The accuracy for the XGB in the TEST set is {:.2f}\".format(final_cl.score(X_test, y_test)))\n",
    "\n",
    "y_pred = pd.Series(final_cl.predict(X_train))\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(confusion_matrix(y_train, y_pred))\n",
    "display(cohen_kappa_score(y_train, y_pred))\n",
    "\n",
    "y_pred = pd.Series(final_cl.predict(X_test))\n",
    "display(pd.DataFrame(y_pred).value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))\n",
    "display(cohen_kappa_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f688",
   "metadata": {},
   "source": [
    "## Feature extraction-SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0862ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(final_cl)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470aa899",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0, :], X.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35438ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot( ' Persistent EPS in the Last Four Seasons', shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35107792",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d19bf",
   "metadata": {},
   "source": [
    "# K-fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(4, 12))\n",
    "\n",
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos CV-10 a todos los modelos para tner una mejor estimacion del accuracy y menor varianza\n",
    "nfolds = 10\n",
    "models = [knn, clf, xgb_cl]\n",
    "cv_scores = np.zeros((len(models), nfolds))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    scores = cross_val_score(model, X, y, scoring='roc', cv=nfolds)\n",
    "    cv_scores[i] = scores\n",
    "    \n",
    "cv_df = pd.DataFrame(cv_scores, index=[models])\n",
    "cv_df['mean_score'] = cv_df.mean(1)\n",
    "cv_df['std_score'] = cv_df.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea41b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
